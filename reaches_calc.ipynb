{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Reaches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully separated into yearly files!\n"
     ]
    }
   ],
   "source": [
    "# Separating Final_dataset.csv into 15 separate files\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(\"input_folder/Final_dataset.csv\")\n",
    "\n",
    "# Group data by year\n",
    "year_groups = df.groupby('year')\n",
    "\n",
    "# Function to write each year data to a separate file\n",
    "def write_year_data(year, data):\n",
    "  filename = f\"input_folder/junction_counts_{year}.csv\" \n",
    "  data.groupby('id')\n",
    "  data.to_csv(filename, index=False)\n",
    "\n",
    "# Loop through each year group and write data to separate files\n",
    "for year, group_data in year_groups:\n",
    "  write_year_data(year, group_data)\n",
    "\n",
    "print(\"Data successfully separated into yearly files!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Time Invariant*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Calculate the reaches of the time invariant features\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') # This should probably be changed to a more sofisticated system at some point. i.e. install the package\n",
    "\n",
    "import math\n",
    "\n",
    "from heapq import heappush, heappop\n",
    "\n",
    "from ast import literal_eval\n",
    "from data_wrangler.dataset import Dataset\n",
    "\n",
    "INPUT_FOLDER = 'input_folder'\n",
    "OUTPUT_FOLDER = 'output_folder'\n",
    "\n",
    "JUNCTION_FILE = f'{INPUT_FOLDER}/junction_counts_2008.csv'\n",
    "\n",
    "CRIME_SIGMA = 132\n",
    "STANDARD_DEVIATION = 400\n",
    "\n",
    "junctions = Dataset.load_file(JUNCTION_FILE)\n",
    "junctions.convert_properties({\n",
    "    'id': int,\n",
    "    'crime_count': int,\n",
    "    'store_count': int,\n",
    "    'police_count': int,\n",
    "    'transit_count': int,\n",
    "    'graffiti_count': int,\n",
    "    'homeless_shelter_count': int,\n",
    "    'traffic_signal_count': int,\n",
    "    'street_lighting_poles_count': int,\n",
    "    'schools_count': int,\n",
    "    'neighbors': lambda v : literal_eval(v) if v else []\n",
    "})\n",
    "\n",
    "def normal_dst(distance, standard_deviation):\n",
    "    scale = 1 / (2 * math.pi * (standard_deviation ** 2))\n",
    "    power = distance ** 2 / (2 * standard_deviation ** 2)\n",
    "    distribution = math.exp(-power)\n",
    "    return scale * distribution\n",
    "\n",
    "def reach_dst(distance, scale):\n",
    "    \"\"\" Calculate a modified version of Borgatti's reach formula\n",
    "    \n",
    "    TODO: Check that convergence is important and that if is whether we actually need to cube the denominator\n",
    "    The range formula is:  sumweight * 1 / (dst_scale * dst + 1) ^ 2\n",
    "    We have +1 because we want distance of zero to be constant with respect to dst_scale\n",
    "    We cube the denominator because this causes it to converge\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1 / ((distance / scale + 1) ** 3)\n",
    "\n",
    "def calculate_reach(junction, properties, dst_func, limit=float('inf')):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        junction (Row): The junction to calculate the reach for\n",
    "        prop (str): The property to use for junction weights\n",
    "        dst_scale (float): The value to scale distance by. Should be in the range (0, 1]. Likely close to zero.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated reach.\n",
    "    \"\"\"\n",
    "    reaches = { key: 0 for key in properties}\n",
    "    visited = set()\n",
    "    queue = []\n",
    "    heappush(queue, (0, junction['id']))\n",
    "    while queue:\n",
    "        dst, next_jun = heappop(queue)\n",
    "        if next_jun in visited: continue\n",
    "        visited.add(next_jun)\n",
    "        if dst > limit: continue\n",
    "        \n",
    "        # The range formula is: weight * 1 / (dst_scale * dst + 1) ^ 2\n",
    "        # We have +1 because we want distance of zero to be constant with respect to dst_scale\n",
    "        # We square the denominator because this causes it to converge\n",
    "        \n",
    "        # Update the range values\n",
    "        crime_dst = normal_dst(dst, CRIME_SIGMA)\n",
    "        scaled_dst = dst_func(dst)\n",
    "        for key in properties:\n",
    "            if key == 'crime_reach':\n",
    "                reaches[key] += junctions[next_jun][properties[key]] * crime_dst\n",
    "            else:\n",
    "                reaches[key] += junctions[next_jun][properties[key]] * scaled_dst\n",
    "              \n",
    "        for neighbor, delta, s_id in junctions[next_jun]['neighbors']:\n",
    "            if neighbor in visited: continue\n",
    "            neighbor_dst = dst + delta\n",
    "            heappush(queue, (neighbor_dst, neighbor))\n",
    "    return reaches\n",
    "\n",
    "def calculate_reaches(junctions, properties, dst_func, limit=float('inf')):\n",
    "    highest = { key: 0 for key in properties}\n",
    "    \n",
    "    for i, junction in enumerate(junctions):\n",
    "        reaches = calculate_reach(junction, properties, dst_func, limit)\n",
    "        for key in reaches:\n",
    "            junction[key] = reaches[key]\n",
    "            highest[key] = max(highest[key], reaches[key])\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'\\rCalculated {i+1}/{len(junctions)}           ', end='')\n",
    "    print(f'\\rCalculated {len(junctions)}/{len(junctions)}        ')\n",
    "    print(\"Normalizing\")\n",
    "    for junction in junctions:\n",
    "        for key in properties:\n",
    "            junction[key] /= highest[key]\n",
    "    print(\"Done\")\n",
    "    \n",
    "calculate_reaches(\n",
    "    junctions, \n",
    "    {\n",
    "        # 'crime_reach': 'crime_count',\n",
    "        # 'store_reach': 'store_count',\n",
    "        # 'police_reach': 'police_count',\n",
    "        # 'transit_reach': 'transit_count',\n",
    "        'graffiti_reach': 'graffiti_count',\n",
    "        'homeless_shelter_reach': 'homeless_shelter_count',\n",
    "        'traffic_signal_reach': 'traffic_signal_count',\n",
    "        'street_lighting_poles_reach': 'street_lighting_poles_count',\n",
    "        'schools_reach': 'schools_count'\n",
    "    }, \n",
    "    lambda dst: normal_dst(dst, STANDARD_DEVIATION),\n",
    "    limit=1000\n",
    ")\n",
    "junctions.write_to_file(f'{OUTPUT_FOLDER}/reach_junctions_time_invariant.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Time Variant*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n",
      "Calculated 6179/6179           \n",
      "Normalizing\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Calculate the reaches of the time variant features for each year\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') # This should probably be changed to a more sofisticated system at some point. i.e. install the package\n",
    "\n",
    "import math\n",
    "\n",
    "from heapq import heappush, heappop\n",
    "\n",
    "from ast import literal_eval\n",
    "from data_wrangler.dataset import Dataset\n",
    "\n",
    "def normal_dst(distance, standard_deviation):\n",
    "    scale = 1 / (2 * math.pi * (standard_deviation ** 2))\n",
    "    power = distance ** 2 / (2 * standard_deviation ** 2)\n",
    "    distribution = math.exp(-power)\n",
    "    return scale * distribution\n",
    "\n",
    "def reach_dst(distance, scale):\n",
    "    \"\"\" Calculate a modified version of Borgatti's reach formula\n",
    "    \n",
    "    TODO: Check that convergence is important and that if is whether we actually need to cube the denominator\n",
    "    The range formula is:  sumweight * 1 / (dst_scale * dst + 1) ^ 2\n",
    "    We have +1 because we want distance of zero to be constant with respect to dst_scale\n",
    "    We cube the denominator because this causes it to converge\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1 / ((distance / scale + 1) ** 3)\n",
    "\n",
    "def calculate_reach(junction, properties, dst_func, limit=float('inf')):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        junction (Row): The junction to calculate the reach for\n",
    "        prop (str): The property to use for junction weights\n",
    "        dst_scale (float): The value to scale distance by. Should be in the range (0, 1]. Likely close to zero.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated reach.\n",
    "    \"\"\"\n",
    "    reaches = { key: 0 for key in properties}\n",
    "    visited = set()\n",
    "    queue = []\n",
    "    heappush(queue, (0, junction['id']))\n",
    "    while queue:\n",
    "        dst, next_jun = heappop(queue)\n",
    "        if next_jun in visited: continue\n",
    "        visited.add(next_jun)\n",
    "        if dst > limit: continue\n",
    "        \n",
    "        # The range formula is: weight * 1 / (dst_scale * dst + 1) ^ 2\n",
    "        # We have +1 because we want distance of zero to be constant with respect to dst_scale\n",
    "        # We square the denominator because this causes it to converge\n",
    "        \n",
    "        # Update the range values\n",
    "        crime_dst = normal_dst(dst, CRIME_SIGMA)\n",
    "        scaled_dst = dst_func(dst)\n",
    "        for key in properties:\n",
    "            if key == 'crime_reach':\n",
    "                reaches[key] += junctions[next_jun][properties[key]] * crime_dst\n",
    "            else:\n",
    "                reaches[key] += junctions[next_jun][properties[key]] * scaled_dst\n",
    "              \n",
    "        for neighbor, delta, s_id in junctions[next_jun]['neighbors']:\n",
    "            if neighbor in visited: continue\n",
    "            neighbor_dst = dst + delta\n",
    "            heappush(queue, (neighbor_dst, neighbor))\n",
    "    return reaches\n",
    "\n",
    "def calculate_reaches(junctions, properties, dst_func, limit=float('inf')):\n",
    "    highest = { key: 0 for key in properties}\n",
    "    \n",
    "    for i, junction in enumerate(junctions):\n",
    "        reaches = calculate_reach(junction, properties, dst_func, limit)\n",
    "        for key in reaches:\n",
    "            junction[key] = reaches[key]\n",
    "            highest[key] = max(highest[key], reaches[key])\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'\\rCalculated {i+1}/{len(junctions)}           ', end='')\n",
    "    print(f'\\rCalculated {len(junctions)}/{len(junctions)}        ')\n",
    "    print(\"Normalizing\")\n",
    "    for junction in junctions:\n",
    "        for key in properties:\n",
    "            junction[key] /= highest[key]\n",
    "    print(\"Done\")\n",
    "\n",
    "INPUT_FOLDER = 'input_folder'\n",
    "OUTPUT_FOLDER = 'output_folder'\n",
    "\n",
    "CRIME_SIGMA = 132\n",
    "STANDARD_DEVIATION = 400\n",
    "\n",
    "for year in range(2008, 2024):\n",
    "    junction_file = f'{INPUT_FOLDER}/junction_counts_{year}.csv'\n",
    "    junctions = Dataset.load_file(junction_file)\n",
    "    junctions.convert_properties({\n",
    "    'id': int,\n",
    "    'crime_count': int,\n",
    "    'store_count': int,\n",
    "    'police_count': int,\n",
    "    'transit_count': int,\n",
    "    'graffiti_count': int,\n",
    "    'homeless_shelter_count': int,\n",
    "    'traffic_signal_count': int,\n",
    "    'street_lighting_poles_count': int,\n",
    "    'schools_count': int,\n",
    "    'neighbors': lambda v : literal_eval(v) if v else []\n",
    "    })\n",
    "    calculate_reaches(\n",
    "        junctions, \n",
    "        {\n",
    "            'crime_reach': 'crime_count',\n",
    "            'store_reach': 'store_count',\n",
    "            'police_reach': 'police_count',\n",
    "            'transit_reach': 'transit_count',\n",
    "            # 'graffiti_reach': 'graffiti_count',\n",
    "            # 'homeless_shelter_reach': 'homeless_shelter_count',\n",
    "            # 'traffic_signal_reach': 'traffic_signal_count',\n",
    "            # 'street_lighting_poles_reach': 'street_lighting_poles_count',\n",
    "            # 'schools_reach': 'schools_count'\n",
    "        }, \n",
    "        lambda dst: normal_dst(dst, STANDARD_DEVIATION),\n",
    "        limit=1000\n",
    "    )\n",
    "    junctions.write_to_file(f'{OUTPUT_FOLDER}/reach_junctions_time_variant_{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted all CSV files in output_folder to Excel!\n"
     ]
    }
   ],
   "source": [
    "# Convert all csv files in folder to excel\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the folder path containing CSV files\n",
    "folder_path = \"output_folder\"  # Replace with your actual folder path\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "  # Check if the file is a CSV file\n",
    "  if filename.endswith(\".csv\"):\n",
    "    # Construct the full path to the CSV file\n",
    "    csv_file = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Read the CSV data using pandas\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Construct the output filename (replace '.csv' with '.xlsx')\n",
    "    xlsx_file = os.path.splitext(filename)[0] + \".xlsx\"\n",
    "    \n",
    "    # Save the DataFrame to an Excel file\n",
    "    df.to_excel(os.path.join(folder_path, xlsx_file), index=False)  # Set index=False to exclude row index\n",
    "\n",
    "print(f\"Successfully converted all CSV files in {folder_path} to Excel!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
