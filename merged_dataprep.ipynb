{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the missing values in the new features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data\\\\panel_dataset.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create a list of years to interpolate\n",
    "years_to_interpolate = list(range(2008, 2024))\n",
    "\n",
    "# Define the interpolation function\n",
    "def interpolate_values(data_2006, data_2016, neighborhood, row, years):\n",
    "    results = []\n",
    "    for year in years:\n",
    "        if year != 2011 and year != 2016:    # skip over 2011 and 2016\n",
    "            interpolated_row = row.copy()\n",
    "            interpolated_row['Neighborhood'] = neighborhood # Add enighborhood value\n",
    "            interpolated_row['Year'] = year\n",
    "            for column in df.columns[2:]:  # Skip 'Neighborhood' and 'Year' columns\n",
    "                y1 = data_2006.at[row.name, column]\n",
    "                y2 = data_2016.at[row.name, column]\n",
    "                x = year\n",
    "                x1 = 2006\n",
    "                x2 = 2016\n",
    "                y = y1 + (((x - x1) * (y2 - y1)) / (x2 - x1))\n",
    "                interpolated_row[column] = y\n",
    "            results.append(interpolated_row)\n",
    "    return results\n",
    "\n",
    "# Extract unique neighborhoods\n",
    "neighborhoods = df['Neighborhood'].unique()\n",
    "\n",
    "# Initialize an empty list to collect interpolated rows\n",
    "interpolated_rows = []\n",
    "\n",
    "# Iterate through each neighborhood\n",
    "for neighborhood in neighborhoods:\n",
    "    neighborhood_data = df[df['Neighborhood'] == neighborhood]\n",
    "    data_2006 = neighborhood_data[neighborhood_data['Year'] == 2006].set_index('Neighborhood').drop(columns=['Year'])\n",
    "    data_2016 = neighborhood_data[neighborhood_data['Year'] == 2016].set_index('Neighborhood').drop(columns=['Year'])\n",
    "    \n",
    "    if not data_2006.empty and not data_2016.empty:\n",
    "        # Interpolate values and extend the list of interpolated rows\n",
    "        for index, row in data_2006.iterrows():\n",
    "            interpolated_rows.extend(interpolate_values(data_2006, data_2016, neighborhood, row, years_to_interpolate))\n",
    "\n",
    "# Convert the list of interpolated rows to a DataFrame\n",
    "interpolated_df = pd.DataFrame(interpolated_rows)\n",
    "\n",
    "# Concatenate the original and interpolated data\n",
    "result_df = pd.concat([df, interpolated_df], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by 'Neighborhood' and 'Year'\n",
    "result_df = result_df.sort_values(by=['Neighborhood', 'Year'])\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "result_df.to_excel('data\\\\panel_dataset_interpolated.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the rows with irrelevant years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved to data\\new_features_updated.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the interpolated dataset\n",
    "file_path = 'data\\\\panel_dataset_interpolated.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filter rows within the range of 2008-2023\n",
    "df_filtered = df[(df['Year'] >= 2008) & (df['Year'] <= 2023)]\n",
    "\n",
    "# Save the filtered DataFrame to a new Excel file\n",
    "output_file = 'data\\\\new_features_updated.xlsx'\n",
    "df_filtered.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Filtered dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the corresponding neighborhood_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with neighborhood IDs saved to data\\new_features_updated_ids.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the updated features dataset with neighborhood_id column added\n",
    "file_path = 'data\\\\new_features_updated.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Define the mapping of neighborhood names to IDs\n",
    "neighborhood_mapping = {\n",
    "    'West End': 14, 'Downtown': 1, 'Strathcona': 20, 'Grandview': 16, 'Hastings': 2,\n",
    "    'West Point Grey': 22, 'Kitsilano': 19, 'Fairview': 11, 'Mount Pleasant': 12, 'Dunbar': 10,\n",
    "    'Arbutus': 15, 'Shaughnessy': 8, 'South Cambie': 7, 'Riley Park': 6, 'Kensington': 17,\n",
    "    'Renfrew': 13, 'Kerrisdale': 3, 'Oakridge': 5, 'Sunset': 21, 'Victoria': 9,\n",
    "    'Killarney': 18, 'Marpole': 4\n",
    "}\n",
    "\n",
    "# Map neighborhood names to IDs and update the neighborhood_id column\n",
    "df['neighborhood_id'] = df['Neighborhood'].map(neighborhood_mapping)\n",
    "\n",
    "# Save the updated DataFrame with neighborhood IDs to a new Excel file\n",
    "output_file = 'data\\\\new_features_updated_ids.xlsx'\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Updated dataset with neighborhood IDs saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the Merged panel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset with updated features saved to data\\merged_final_with_updated_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "file_merged = 'data\\\\merged_Final_merf.xlsx'\n",
    "file_updated = 'data\\\\new_features_updated_ids.xlsx'\n",
    "\n",
    "df_merged = pd.read_excel(file_merged)\n",
    "df_updated = pd.read_excel(file_updated)\n",
    "\n",
    "# Perform the merge based on 'Year' and 'neighborhood_id'\n",
    "merged_df = pd.merge(df_merged, df_updated, on=['Year', 'neighborhood_id'], how='left')\n",
    "\n",
    "# Drop the original 'Neighborhood' column from df_merged if needed\n",
    "merged_df.drop(columns=['Neighborhood'], inplace=True)  # Uncomment if 'Neighborhood' is already in df_updated\n",
    "\n",
    "# Save the merged DataFrame to a new Excel file\n",
    "output_file = 'data\\\\merged_final_with_updated_features_double.xlsx'\n",
    "merged_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Merged dataset with updated features saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
